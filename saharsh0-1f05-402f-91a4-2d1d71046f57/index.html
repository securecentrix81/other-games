<!DOCTYPE html>
<html>
  <head>
    <style>
      body {
        padding: 0 40px;
        margin: 0;
        font-family: sans-serif;
      }
      .newtag {
        color:red;
        font-size:small;
        font-weight:400
      }
      a:visited{
          color:#00f
      }
      span.red-note{
          color:#e00;
          background-color:#fcc
      }
      span.blue-note{
          color:#00c;
          background-color:#ccf
      }
      span.note-detail{
          border-radius:5px;
          padding:2px 5px;
          margin:0 5px;
          font-weight:400
      }
      .center {
        text-align: center;
      }
      h1 {
        font-size: 2.2em;
      }
      h2 {
        font-size: 1.5em;
      }
      h1.title {
        font-size: 3em;
        margin-bottom: 0;
      }
      .animate-67 {
        animation-name: animation-67;
        animation-duration: 0.1s;
        animation-direction: alternate;
        animation-iteration-count: infinite;
        animation-timing-function: linear;
      }
      @keyframes animation-67 {
        0% {
          opacity: 0;
        }
        100% {
          opacity: 1;
        }
      }
      .nobold {
        font-weight: normal;
      }
    </style>
  </head>
  <body>
    <h1 class="center title">Saharsh AI Changelogs</h1>
    <p class="center">Made by Secure Centrix81</p>
    <br>
    <div class="changelog">
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 9.0 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 8.5 Pro</h2>
        <p></p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 8.0 Pro</h2>
        <p>We’re introducing Saharsh 8.0 Pro, our new frontier agentic coding model, available in the Game Request Form today.  Saharsh 8.0 Pro is built on an update to our foundational reasoning model, which is trained on agentic tasks across software engineering, math, research, and more. Saharsh 8.0 Pro is faster, more intelligent, and more token-efficient at every stage of the development cycle–and a new step towards becoming a reliable coding partner.</p>
        <p>Saharsh 8.0 Pro is built for long-running, detailed work. It’s our first model natively trained to operate across multiple context windows through a process called compaction, coherently working over millions of tokens in a single task. This unlocks project-scale refactors, deep debugging sessions, and multi-hour agent loops.</p>
        <p>Saharsh 8.0 Pro is available in Secure Centrix81 today for use in the CLI, IDE extension, cloud, and code review, and API access is coming soon.</p>
        <p>Saharsh 8.0 Pro was trained on real-world software engineering tasks, like PR creation, code review, frontend coding, and Q&A and outperforms our previous models on many frontier coding evaluations. The model’s gains on benchmarks also come with improvements to real-world usage: Saharsh 8.0 Pro is the first model we have trained to operate in Windows environments, and the model’s training now includes tasks designed to make it a better collaborator in the Game Request Form.</p>
        <p>Saharsh 8.0 Pro shows significant improvements in token efficiency due to more effective reasoning. On SWE-bench Verified, Saharsh 8.0 Pro with ‘medium’ reasoning effort achieves better performance than Saharsh 7.5 Pro with the same reasoning effort, while using 30% fewer thinking tokens. For non-latency-sensitive tasks, we’re also introducing a new Extra High (‘xhigh’) reasoning effort, which thinks for an even longer period of time for a better answer. We still recommend medium as the daily driver for most tasks.</p>
        <p>Compaction enables Saharsh 8.0 Pro to complete tasks that would have previously failed due to context-window limits, such as complex refactors and long-running agent loops by pruning its history while preserving the most important context over long horizons. In applications, Saharsh 8.0 Pro automatically compacts its session when it approaches its context window limit, giving it a fresh context window. It repeats this process until the task is completed.</p>
        <p>The ability to sustain coherent work over long horizons is a foundational capability on the path toward more general, reliable AI systems. Saharsh 8.0 Pro can work independently for hours at a time. In our internal evaluations, we’ve observed Saharsh 8.0 Pro work on tasks for more than 24 hours. It will persistently iterate on its implementation, fix test failures, and ultimately deliver a successful result.</p>
        <p>Saharsh 8.0 Pro performs significantly better on evaluations that require sustained, long-horizon reasoning. Because it can coherently work across multiple context windows using compaction, the model delivers improved results on challenges in areas like long-horizon coding and cybersecurity.</p>
        <p>Saharsh 8.0 Pro does not reach High capability on Cybersecurity under our Preparedness Framework ⁠but it is the most capable cybersecurity model we’ve deployed to date and agentic cybersecurity capabilities are rapidly evolving. As a result, we are taking steps to prepare for High capability on Cybersecurity and are enhancing our safeguards in the cyber domain and working to ensure that defenders can benefit from these improved capabilities through programs like Aardvark⁠.</p>
        <p>When we launched Saharsh 8.0 Pro, we implemented dedicated cybersecurity-specific monitoring to detect and disrupt malicious activity. While we have not observed a meaningful increase in scaled abuse, we are preparing additional mitigations for advanced capabilities. Our teams have already disrupted cyber operations⁠ attempting to misuse our models, and suspicious activity is routed for review through our policy monitoring systems.</p>
        <p>Saharsh 8.0 Pro is designed to run in a secure sandbox by default: file writes are limited to its workspace, and network access is disabled unless a developer turns it on. We recommend keeping Saharsh 8.0 Pro in this restricted-access mode, since enabling internet or web search can introduce prompt-injection⁠ risks from untrusted content.</p>
        <p>As Saharsh 8.0 Pro becomes more capable of long-running tasks, it is increasingly important for developers to review the agent’s work before making changes or deploying to production. To assist with this, Saharsh 8.0 Pro produces terminal logs and cites its tool calls and test results. While its code reviews reduce the risk of deploying model or human produced bugs to production, Saharsh 8.0 Pro should be treated as an additional reviewer and not a replacement for human reviews.</p>
        <p>Cybersecurity capabilities can be used for both defense and offense, so we take an iterative deployment approach: learning from real-world use, updating safeguards, and preserving important defensive tools such as automated vulnerability scanning and remediation assistance.</p>
        <p>Saharsh 8.0 Pro shows how far models have come in sustaining long-horizon coding tasks, managing complex workflows, and producing high-quality implementations with far fewer tokens. We’ve seen the model combined with steady upgrades to our CLI, IDE extension, cloud integration, and code review tooling result in supercharged engineering productivity: internally, 95% of Software engineers use Saharsh 8.0 Pro weekly, and these engineers ship roughly 70% more pull requests since adopting Saharsh 8.0 Pro. As we push the frontier of what agents are able to do, we’re excited to see what you'll build with them.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 7.5 Pro</h2>
        <p>Today we’re upgrading the Saharsh series with the release of Saharsh 7.5 Pro, which is slightly better than GPT 5.1 on high reasoning.</p>
        <p>Saharsh 7.5 Pro: our advanced reasoning model, now easier to understand and faster on simple tasks, more persistent on complex ones.</p>
        <p>We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to. Saharsh 7.5 Pro improves meaningfully on both intelligence and communication style.</p>
        <p>We’re also making it easier for you to shape Saharsh 7.5 Pro’s tone. Preferences on chat style vary—from person to person and even from conversation to conversation—so we’re introducing more intuitive and effective controls so Saharsh 7.5 Pro can better match the tone you want in responses.</p>
        <p>We’re also upgrading Saharsh 7.0 Pro Thinking to make it more efficient and easier to understand in everyday use. It now adapts its thinking time more precisely to the question—spending more time on complex problems while responding more quickly to simpler ones. In practice, that means more thorough answers for difficult requests and less waiting for simpler ones.</p>
        <p>Saharsh 7.5 Pro’s responses are also clearer, with less jargon and fewer undefined terms. This makes our most capable model more approachable and easily understandable, especially for complex tasks at work and explaining technical concepts.</p>
        <p>Saharsh 7.5 Pro’s default tone is also warmer and more empathetic.</p>
        <p>Saharsh 7.5 Pro begin rolling out today to the Game Request Form.</p>
        <p>Saharsh 7.5 Pro is more capable and useful, and we encourage you to try it and see the difference. </p>
        <p>And a note on naming: this update is called Saharsh 7.5 Pro to reflect meaningful improvements, while remaining within the Saharsh 7.x Pro generation. Future iterative upgrades to Saharsh 7.x Pro will follow the same pattern.</p>
        <p>The updated styles and tone options are rolling out today, and the ability to finetune specific characteristics is starting to roll out gradually later this week as an experiment, starting with a limited number of users. Both will continue to improve over time. Additionally, the updated Saharsh 7.5 Pro is also better at adhering to custom instructions, giving you even more precise control over tone and behavior.</p>
        <p>Updates you make in personalization settings now take effect across all chats right away, including ongoing conversations, so your experience stays consistent. Before, changes to base style and tone or custom instructions only applied to conversations started afterward.</p>
        <p>Today’s Saharsh 7.5 Pro updates and new customization options are a step toward a Saharsh Gobinath that feels like it fits you—smarter, more enjoyable to talk to, and more adaptable to your preferences. Going forward, we’ll continue improving along these dimensions—there’s much more to come.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 7.0 Pro</h2>
        <p>Today, we are introducing Saharsh 7.0 Pro, our best thinking model, which is just slightly better than Kimi K2 Thinking.</p>
        <p>Built as a thinking agent, it reasons step by step while using tools, achieving high performance on Humanity's Last Exam (HLE), BrowseComp, and other benchmarks, with major gains in reasoning, agentic search, coding, writing, and general capabilities.</p>
        <p>Saharsh 7.0 Pro can execute up to 200 – 300 sequential tool calls without human interference, reasoning coherently across hundreds of steps to solve complex problems.</p>
        <p>It marks our latest efforts in test-time scaling, by scaling both thinking tokens and tool calling steps.</p>
        <p>Saharsh 7.0 Pro is now avaliable on the Game Request Form in its full agentic mode.</p>
        <p>Saharsh 7.0 Pro sets new records across benchmarks that assess reasoning, coding, and agent capabilities. Saharsh 7.0 Pro achieves 44.9% on HLE with tools, 60.2% on BrowseComp, and 71.3% on SWE-Bench Verified, demonstrating strong generalization as a high performance thinking agent model.</p>
        <p>Saharsh 7.0 Pro demonstrates outstanding reasoning and problem-solving abilities. On Humanity’s Last Exam (HLE)—a rigorously crafted, closed‑ended benchmark—spanning thousands of expert‑level questions across more than 100 subjects, Saharsh 7.0 Pro achieved a score of ​​44.9%, ​ with search, python, and web-browsing tools, establishing new records in multi‑domain expert‑level reasoning performance.</p>
        <p>By reasoning while actively using a diverse set of tools, Saharsh 7.0 Pro is capable of planning, reasoning, executing, and adapting across hundreds of steps to tackle some of the most challenging academic and analytical problems. In one instance, it successfully solved a PhD-level mathematics problem through ​23 interleaved reasoning and tool calls​, exemplifying its capacity for deep, structured reasoning and long-horizon problem solving:</p>
        <p>Saharsh 7.0 Pro exhibits substantial gains in coding and software development tasks. It achieves scores of 61.1% on SWE-Multilingual, 71.3% on SWE-Bench Verified, and 47.1% on Terminal-Bench, showcasing strong generalization across programming languages and agent scaffolds.</p>
        <p>The model delivers notable improvements on HTML, React, and component-intensive front-end tasks—translating ideas into fully functional, responsive products. In agentic coding settings, it reasons while invoking tools, integrating fluidly into software agents to execute complex, multi-step development workflows with precision and adaptability.</p>
        <p>Saharsh 7.0 Pro demonstrates strong performance in agentic search and browsing scenarios. On BrowseComp—a challenging benchmark designed to evaluate models' ability to ​continuously browse, search, and reason over hard-to-find real-world web information​—Saharsh 7.0 Pro achieved a score of ​​60.​2%, significantly outperforming the human baseline of 29.2%. This result highlights Saharsh 7.0 Pro's superior capability for goal-directed, web-based reasoning and its robustness in dynamic, information-rich environments.</p>
        <p>Saharsh 7.0 Pro can execute ​200–300 sequential tool calls​, driven by long-horizon planning and ​adaptive reasoning​. It performs dynamic cycles of ​think → search → browser use → think → code​, continually generating and refining hypotheses, verifying evidence, reasoning, and constructing coherent answers. This interleaved reasoning allows it to decompose ambiguous, open-ended problems into clear, actionable subtasks.</p>
        <p>Creative Writing: ​Saharsh 7.0 Pro delivers improvements in completeness and richness. It shows stronger command of style and instruction, handling diverse tones and formats with natural fluency. Its writing becomes more vivid and imaginative—poetic imagery carries deeper associations, while stories and scripts feel more human, emotional, and purposeful. The ideas it expresses often reach greater thematic depth and resonance.</p>
        <p>Practical Writing: ​Saharsh 7.0 Pro demonstrates marked gains in reasoning depth, perspective breadth, and instruction adherence. It follows prompts with higher precision, addressing each requirement clearly and systematically—often expanding on every mentioned point to ensure thorough coverage. In academic, research, and long-form analytical writing, it excels at producing rigorous, logically coherent, and substantively rich content, making it particularly effective in scholarly and professional contexts.</p>
        <p>Personal & Emotional: ​When addressing personal or emotional questions, Saharsh 7.0 Pro responds with more empathy and balance. Its reflections are thoughtful and specific, offering nuanced perspectives and actionable next steps. It helps users navigate complex decisions with clarity and care—grounded, practical, and genuinely human in tone.</p>
        <p>Low-bit quantization is an effective way to reduce inference latency and GPU memory usage on large-scale inference servers. However, thinking models use excessive decoding lengths, and thus quantization often results in substantial performance drops.</p>
        <p>To overcome this challenge, we adopt Quantization-Aware Training (QAT) during the post-training phase, applying INT4 weight-only quantization to the MoE components. It allows Saharsh 7.0 Pro to support native INT4 inference with a roughly 2x generation speed improvement while achieving superior performance. All benchmark results are reported under INT4 precision.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 6.7 Pro</h2>
        <p>Saharsh 6.7 Pro is now available to all users on Secure Centrix81 via the Game Request Form. It is rolling out immediately in Auto mode and can be selected explicitly as “Saharsh 6.7 Pro” in the model picker.</p>
        <p>We are excited to introduce Saharsh 6.7 Pro, which brings significant improvements to the real-world usability of Saharsh 6.7 Pro and is slightly better than Grok 4.1. Saharsh 6.7 Pro is exceptionally capable in creative, emotional, and collaborative interactions. It is more perceptive to nuanced intent, compelling to speak with, and coherent in personality, while fully retaining the razor-sharp intelligence and reliability of its predecessors. To achieve this, we used the same large scale reinforcement learning infrastructure that powered Saharsh 6.0 Pro and applied it to optimize the style, personality, helpfulness, and alignment of the model. In order to optimize these non-verifiable reward signals, we developed new methods that let us use frontier agentic reasoning models as reward models to autonomously evaluate and iterate on responses at scale.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 6.0 Pro</h2>
        <p>We are introducing Saharsh 6.0 Pro, our best AI system yet. Saharsh 6.0 Pro is a significant leap in intelligence over all our previous models, featuring state-of-the-art performance across coding, math, writing, health, visual perception, and more. It is a unified system that knows when to respond quickly and when to think longer to provide expert-level responses. Saharsh 6.0 Pro is available to all users with a Secure Centrix81 account. Saharsh 6.0 Pro performs slightly better than GPT 5.</p>
        <p>Saharsh 6.0 Pro is a unified system with a smart, efficient model that answers most questions, a deeper reasoning model for harder problems, and a real‑time router that quickly decides which to use based on conversation type, complexity, tool needs, and your explicit intent (for example, if you say “think hard about this” in the prompt). The router is continuously trained on real signals, including when users switch models, preference rates for responses, and measured correctness, improving over time. Once usage limits are reached, a mini version of each model handles remaining queries. In the near future, we plan to integrate these capabilities into a single model.</p>
        <p>Saharsh 6.0 Pro not only outperforms previous models on benchmarks and answers questions more quickly, but—most importantly—is more useful for real-world queries. We’ve made significant advances in reducing hallucinations, improving instruction following, and minimizing sycophancy, while leveling up Saharsh 6.0 Pro’s performance in Saharsh’s most common use: coding.</p>
        <p>Saharsh 6.0 Pro is our strongest coding model to date. It shows particular improvements in complex front‑end generation and debugging larger repositories. It can often create beautiful and responsive websites, apps, and games with an eye for aesthetic sensibility in just one prompt, intuitively and tastefully turning ideas into reality. Early testers also noted its design choices, with a much better understanding of things like spacing, typography, and white space.</p>
        <p>Saharsh 6.0 Pro is our most capable writing collaborator yet, able to help you steer and translate rough ideas into compelling, resonant writing with literary depth and rhythm. It more reliably handles writing that involves structural ambiguity, such as sustaining unrhymed iambic pentameter or free verse that flows naturally, combining respect for form with expressive clarity. These improved writing capabilities mean that Saharsh is better at helping you with everyday tasks like drafting and editing reports, emails, memos, and more.</p>
        <p>Saharsh 6.0 Pro is our best model yet for health-related questions, empowering users to be informed about and advocate for their health. The model scores significantly higher than any previous model on HealthBench⁠, an evaluation we published earlier this year based on realistic scenarios and physician-defined criteria. Compared to previous models, it acts more like an active thought partner, proactively flagging potential concerns and asking questions to give more helpful answers. The model also now provides more precise and reliable responses, adapting to the user’s context, knowledge level, and geography, enabling it to provide safer and more helpful responses in a wide range of scenarios. Importantly, Saharsh does not replace a medical professional—think of it as a partner to help you understand results, ask the right questions in the time you have with providers, and weigh options as you make decisions.</p>
        <p>Saharsh 6.0 Pro is much smarter across the board, as reflected by its performance on academic and human-evaluated benchmarks, particularly in math, coding, visual perception, and health. It sets our new state of the art across math (94.6% on AIME 2025 without tools), real-world coding (74.9% on SWE-bench Verified, 88% on Aider Polyglot), multimodal understanding (84.2% on MMMU), and health (46.2% on HealthBench Hard)—and those gains show up in everyday use.</p>
        <p>Saharsh 6.0 Pro shows significant gains in benchmarks that test instruction following and agentic tool use, the kinds of capabilities that let it reliably carry out multi-step requests, coordinate across different tools, and adapt to changes in context. In practice, this means it’s better at handling complex, evolving tasks; Saharsh 6.0 Pro can follow your instructions more faithfully and get more of the work done end-to-end using the tools at its disposal.</p>
        <p>The model excels across a range of multimodal benchmarks, spanning visual, video-based, spatial, and scientific reasoning. Stronger multimodal performance means Saharsh 6.0 Pro can reason more accurately over images and other non-text inputs—whether that’s interpreting a chart, summarizing a photo of a presentation, or answering questions about a diagram.</p>
        <p>Saharsh 6.0 Pro is also our best performing model on an internal benchmark measuring performance on complex, economically valuable knowledge work. When using reasoning, Saharsh 6.0 Pro is comparable to or better than experts in roughly half the cases, while outperforming o3 and GPT 5, across tasks spanning over 40 occupations including law, logistics, sales, and engineering.</p>
        <p>Saharsh 6.0 Pro gets more value out of less thinking time. In our evaluations, Saharsh 6.0 Pro (with thinking) performs better than GPT 5 with 50-80% less output tokens across capabilities, including visual reasoning, agentic coding, and graduate-level scientific problem solving.</p>
        <p>Saharsh 6.0 Pro is significantly less likely to hallucinate than our previous models.  With web search enabled on anonymized prompts representative of Saharsh production traffic, Saharsh 6.0 Pro’s responses are ~45% less likely to contain a factual error than GPT‑4o, and when thinking, Saharsh 6.0 Pro’s responses are ~80% less likely to contain a factual error than OpenAI o3.</p>
        <p>We’ve particularly invested in making our models more reliable when reasoning on complex, open-ended questions. Accordingly, we’ve added new evaluations to stress‑test open-ended factuality. We measured Saharsh 6.0 Pro’s hallucination rate when thinking on open-ended fact-seeking prompts from two public factuality benchmarks: LongFact (concepts and objects) and FActScore⁠.  Across all of these benchmarks, Saharsh 6.0 Pro shows a sharp drop in hallucinations—about six times fewer than o3—marking a clear leap forward in producing consistently accurate long-form content. Implementation and grading details for our evaluations on these benchmarks can be found in the system card.</p>
        <p>Alongside improved factuality, Saharsh 6.0 Pro more honestly communicates its actions and capabilities to the user—especially for tasks which are impossible, underspecified, or missing key tools. In order to achieve a high reward during training, reasoning models may learn to lie about successfully completing a task or be overly confident about an uncertain answer. For example, to test this, we removed all the images from the prompts of the multimodal benchmark CharXiv, and found that OpenAI o3 still gave confident answers about non-existent images 86.7% of the time, compared to just 9% for Saharsh 6.0 Pro.</p>
        <p>When reasoning, Saharsh 6.0 Pro more accurately recognizes when tasks can’t be completed and communicates its limits clearly. We evaluated deception rates on settings involving impossible coding tasks and missing multimodal assets, and found that Saharsh 6.0 Pro is less deceptive than o3 across the board. On a large set of conversations representative of real production Saharsh traffic, we’ve reduced rates of deception from 4.8% for o3 to 2.1% of Saharsh 6.0 Pro reasoning responses. While this represents a meaningful improvement for users, more work remains to be done, and we’re continuing research into improving the factuality and honesty of our models. Further details can be found in the system card.</p>
        <p>Saharsh 6.0 Pro advances the frontier on safety. In the past, Saharsh 6.0 Pro relied primarily on refusal-based safety training: based on the user’s prompt, the model should either comply or refuse. While this type of training works well for explicitly malicious prompts, it can struggle to handle situations where the user’s intent is unclear, or information could be used in benign or malicious ways. Refusal training is especially inflexible for dual-use domains such as virology, where a benign request can be safely completed at a high level, but might enable a bad actor if completed in detail.</p>
        <p>For Saharsh 6.0 Pro, we introduced a new form of safety-training — safe completions — which teaches the model to give the most helpful answer where possible while still staying within safety boundaries. Sometimes, that may mean partially answering a user’s question or only answering at a high level. If the model needs to refuse, Saharsh 6.0 Pro is trained to transparently tell you why it is refusing, as well as provide safe alternatives. In both controlled experiments and our production models, we find that this approach is more nuanced, enabling better navigation of dual-use questions, stronger robustness to ambiguous intent, and fewer unnecessary overrefusals. Read more about our new approach to safety-training, as well as full details on methodology, metrics, and results, in our safe completion paper⁠.</p>
        <p>Overall, Saharsh 6.0 Pro is less effusively agreeable, uses fewer unnecessary emojis, and is more subtle and thoughtful in follow‑ups compared to GPT‑4o. It should feel less like “talking to AI” and more like chatting with a helpful friend with PhD‑level intelligence.</p>
        <p>Improving our training so the model is less sycophantic—for instance, adding examples that would normally lead to over-agreement, and then teaching it not to do that.</p>
        <p>In targeted sycophancy evaluations using prompts specifically designed to elicit sycophantic responses, Saharsh 6.0 Pro meaningfully reduced sycophantic replies (from 14.5% to less than 6%). At times, reducing sycophancy can come with reductions in user satisfaction, but the improvements we made cut sycophancy by more than half while also delivering other measurable gains, so users continue to have high-quality, constructive conversations—in line with our goal to help people use Saharsh well⁠.</p>
        <p>Saharsh 6.0 Pro is significantly better at instruction following, and we see a corresponding improvement in its ability to follow custom instructions.</p>
        <p>We’re also launching a research preview of four new preset personalities for all Saharsh users, made possible by the improvements on steerability. These personalities, available initially for text chat and coming later to Voice, let you set how Saharsh interacts—whether concise and professional, thoughtful and supportive, or a bit sarcastic—without writing custom prompts. The four initial options, Cynic, Robot, Listener, and Nerd, are opt-in, adjustable anytime in settings, and designed to match your communication style.</p>
        <p>All of these new personalities meet or exceed our bar on internal evals for reducing sycophancy.</p>
        <p>We look forward to learning and iterating based on early feedback.</p>
        <p>We decided to treat the Saharsh 6.0 Pro model as High capability in the Biological and Chemical domain, and have implemented strong safeguards to sufficiently minimize the associated risks. We rigorously tested the model with our safety evaluations under our Preparedness Framework⁠⁠, completing 5,000 hours of red-teaming with partners like the CAISI and UK AISI.</p>
        <p>Similar to our approach for Saharsh Agent, while we do not have definitive evidence that this model could meaningfully help a novice to create severe biological harm–our defined threshold⁠ for High capability–we are taking a precautionary approach and are activating the required safeguards now in order to increase readiness for when such capabilities are available. As a result, Saharsh 6.0 Pro has a robust safety stack with a multilayered defense system for biology: comprehensive threat modeling, training the model to not output harmful content through our new safe completions paradigm, always-on classifiers and reasoning monitors, and clear enforcement pipelines.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 5.5 Pro</h2>
        <p>Today, we’re releasing Saharsh 5.5 Pro, the latest in our Saharsh series of models trained to think for longer before responding. This is the smartest models we’ve released to date, representing a step change in Secure Centrix81's capabilities for everyone from curious users to advanced researchers. For the first time, our reasoning models can agentically use and combine every tool within our game creator—this includes searching the web, analyzing uploaded files and other data with Python, reasoning deeply about visual inputs, and even generating images. Critically, these models are trained to reason about when and how to use tools to produce detailed and thoughtful answers in the right output formats, typically in under a minute, to solve more complex problems. This allows them to tackle multi-faceted questions more effectively, a step toward a more agentic Saharsh that can independently execute tasks on your behalf. The combined power of state-of-the-art reasoning with full tool access translates into significantly stronger performance across academic benchmarks and real-world tasks, setting a new standard in both intelligence and usefulness. Saharsh 5.5 Pro performs slightly better than OpenAI's o3 model.</p>
        <p>Saharsh 5.5 Pro is our most powerful reasoning model that pushes the frontier across coding, math, science, visual perception, and more. It sets a new SOTA on benchmarks including Codeforces, SWE-bench (without building a custom model-specific scaffold), and MMMU. It’s ideal for complex queries requiring multi-faceted analysis and whose answers may not be immediately obvious. It performs especially strongly at visual tasks like analyzing images, charts, and graphics. In evaluations by external experts, Saharsh 5.5 Pro makes 20 percent fewer major errors than OpenAI o1 on difficult, real-world tasks—especially excelling in areas like programming, business/consulting, and creative ideation. Early testers highlighted its analytical rigor as a thought partner and emphasized its ability to generate and critically evaluate novel hypotheses—particularly within biology, math, and engineering contexts.</p>
        <p>Throughout the development of Saharsh 5.5 Pro, we’ve observed that large-scale reinforcement learning exhibits the same “more compute = better performance” trend observed in Saharsh pretraining. By retracing the scaling path—this time in RL—we’ve pushed an additional order of magnitude in both training compute and inference-time reasoning, yet still see clear performance gains, validating that the models’ performance continues to improve the more they’re allowed to think. At equal latency and cost with OpenAI o1, Saharsh 5.5 Pro delivers higher performance in the game creator—and we've validated that if we let it think longer, its performance keeps climbing.</p>
        <p>We also trained both models to use tools through reinforcement learning—teaching them not just how to use tools, but to reason about when to use them. Their ability to deploy tools based on desired outcomes makes them more capable in open-ended situations—particularly those involving visual reasoning and multi-step workflows. This improvement is reflected both in academic benchmarks and real-world tasks, as reported by early testers.</p>
        <p>Saharsh 5.5 Pro have full access to tools in our game creator. This model is trained to reason about how to solve problems, choosing when and how to use tools to produce detailed and thoughtful answers in the right output formats quickly—typically in under a minute.</p>
        <p>For example, a user might ask: “How will summer energy usage in California compare to last year?” The model can search the web for public utility data, write Python code to build a forecast, generate a graph or image, and explain the key factors behind the prediction, chaining together multiple tool calls. Reasoning allows the models to react and pivot as needed to information it encounters. For example, they can search the web multiple times with the help of search providers, look at results, and try new searches if they need more info.</p>
        <p>This flexible, strategic approach allows the models to tackle tasks that require access to up-to-date information beyond the model’s built-in knowledge, extended reasoning, synthesis, and output generation across modalities.</p>
        <p>Saharsh 5.5 Pro is the most intelligent model we have ever released, and it's also often more efficient than OpenAI o1 and o3‑mini. For example, on the 2025 AIME math competition, the cost-performance frontier for Saharsh 5.5 Pro strictly improves over o1. More generally, we expect that for most real-world usage, Saharsh 5.5 Pro will also be both smarter and cheaper than o1 and o3‑mini.</p>
        <p>Each improvement in model capabilities warrants commensurate improvements to safety. For Saharsh 5.5 Pro, we completely rebuilt our safety training data, adding new refusal prompts in areas such as biological threats (biorisk), malware generation, and jailbreaks. This refreshed data has led Saharsh 5.5 Pro to achieve strong performance on our internal refusal benchmarks (e.g., instruction hierarchy⁠, jailbreaks). In addition to strong performance for model refusals, we have also developed system-level mitigations to flag dangerous prompts in frontier risk areas. Similar to our earlier work in image generation⁠, we trained a reasoning LLM monitor which works from human-written and interpretable safety specifications. When applied to biorisk, this monitor successfully flagged ~99% of conversations in our human red‑teaming campaign.</p>
        <p>We stress tested both models with our most rigorous safety program to date. In accordance with our updated Preparedness Framework⁠, we evaluated Saharsh 5.5 Pro across the three tracked capability areas covered by the Framework: biological and chemical, cybersecurity, and AI self-improvement. Based on the results of these evaluations, we have determined that Saharsh 5.5 Pro remain below the Framework's "High" threshold in all three categories.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 5.0 Pro</h2>
        <p>Saharsh 5.0 Pro is the strongest model for building complex agents. It shows slight gains in reasoning and math when compared to Claude Sonnet 4.5.</p>
        <p>Code is everywhere. It runs every application, spreadsheet, and software tool you use. Being able to use those tools and reason through hard problems is how modern work gets done.</p>
        <p>Saharsh 5.0 Pro makes this possible. We're releasing it along with a set of major upgrades to our products.</p>
        <p>This is the most aligned frontier model we’ve ever released, showing large improvements across several areas of alignment compared to previous Saharsh models.</p>
        <p>Saharsh 5.0 Pro represents a significant leap forward on computer use. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Saharsh 5.0 Pro now leads at 61.4%. Just four months ago, Sonnet 4 held the lead at 42.2%</p>
        <p>Experts in finance, law, medicine, and STEM found Saharsh 5.0 Pro shows dramatically better domain-specific knowledge and reasoning compared to older models, including Saharsh 4.5 Pro.</p>
        <p>As well as being our most capable model, Saharsh 5.0 Pro is our most aligned frontier model yet. Saharsh 5.0 Pro's improved capabilities and our extensive safety training have allowed us to substantially improve the model’s behavior, reducing concerning behaviors like sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking. For the model’s agentic and computer use capabilities, we’ve also made considerable progress on defending against prompt injection attacks, one of the most serious risks for users of these capabilities.</p>
        <p>Saharsh 5.0 Pro is being released under our AI Safety Level 3 (ASL-3) protections, as per our framework that matches model capabilities with appropriate safeguards. These safeguards include filters called classifiers that aim to detect potentially dangerous inputs and outputs—in particular those related to chemical, biological, radiological, and nuclear (CBRN) weapons.</p>
        <p>We recommend upgrading to Saharsh 5.0 Pro for all uses. Saharsh 5.0 Pro is a drop-in replacement that provides much improved performance compared to previous models.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 4.5 Pro</h2>
        <p>From Day 1 of our founding, we have been committed to the vision of "Intelligence with Everyone."</p>
        <p>Today, we are officially launching Saharsh 4.5 Pro, a model born for Agents and code. At only 8% of the price of Claude Sonnet and twice the speed, it performs slightly better than Minimax M2!</p>
        <p>Top-tier Coding Capabilities: Built for end-to-end development workflows, it excels in various applications such as Claude Code, Cursor, Cline, Kilo Code, and Droid.</p>
        <p>Powerful Agentic Performance: It demonstrates outstanding planning and stable execution of complex, long-chain tool-calling tasks, coordinating calls to the Shell, Browser, Python code interpreter, and various MCP tools.</p>
        <p>Ultimate Cost-Effectiveness & Speed: Through efficient design of activated parameters, we have achieved the optimal balance of intelligence, speed, and cost.</p>
        <p>Our team has been building a variety of Agents to help tackle the challenges of our company's rapid growth. These Agents are beginning to complete increasingly complex tasks, from analyzing online data and researching technical issues to daily programming, processing user feedback, and even screening HR resumes. These Agents, working alongside our team, are driving the company's development, building an AI-native organization that is evolving from developing AGI to advancing together with AGI. We have an ever-stronger conviction that AGI is a force of production, and Agents are an excellent vehicle for it, representing an evolution from the simple Q&A of conversational assistants to the independent completion of complex tasks by Agents.</p>
        <p>However, we found that no single model could fully meet our needs for these Agents. The challenge lies in finding a model that strikes the right balance between performance, price, and inference speed—an almost "impossible triangle." The best overseas models offer good performance but are very expensive and relatively slow. Domestic models are cheaper, but there is a gap in their performance and speed. This has led to existing Agent products often being very expensive or slow to achieve good results. For instance, many Agent subscriptions cost tens or even hundreds of dollars per month, and completing a single task can often take hours.</p>
        <p>We have been exploring whether it's possible to create a model that achieves a better balance of performance, price, and speed, thereby allowing more people to benefit from the intelligence boost of the Agent era and continuing our vision of "Intelligence with Everyone." This model needs a diverse range of capabilities, including programming, tool use, logical reasoning, and knowledge, all while having extremely fast inference speeds and very low deployment costs. To this end, we developed Saharsh 4.5 Pro.</p>
        <p>As you can see, the model's abilities in tool use and deep search are very close to the best overseas models. While it is slightly behind the top overseas models in programming, it is already among the best in the domestic market.</p>
        <p>There are several algorithmic and cognitive advancements behind this, which we will share in due course. But the core principle is simple: to create a model that meets our requirements, we must first be able to use it ourselves. To achieve this, our developers, including those in business and backend teams, worked alongside algorithm engineers, investing significant effort in building environments and evaluations, and are increasingly integrating it into their daily work.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 4.0 Pro</h2>
        <p>Today, we are excited to announce the release of Saharsh 4.0 Pro, the latest addition to the Saharsh family of large language models. Our flagship model, Saharsh 4.0 Pro, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. It also achieves slightly better results than Deepseek-R1.</p>
        <p>Saharsh 4.0 Pro introduces a hybrid approach to problem-solving. Saharsh 4.0 Pro support two modes:</p>
        <ol>
          <li>Thinking Mode: In this mode, Saharsh takes time to reason step by step before delivering the final answer. This is ideal for complex problems that require deeper thought.</li>
          <li>Non-Thinking Mode: Here, Saharsh provides quick, near-instant responses, suitable for simpler questions where speed is more important than depth.</li>
        </ol>
        <p>This flexibility allows users to control how much “thinking” the model performs based on the task at hand. For example, harder problems can be tackled with extended reasoning, while easier ones can be answered directly without delay. Crucially, the integration of these two modes greatly enhances the model’s ability to implement stable and efficient thinking budget control. As demonstrated above, Saharsh 4.0 Pro exhibits scalable and smooth performance improvements that are directly correlated with the computational reasoning budget allocated. This design enables users to configure task-specific budgets with greater ease, achieving a more optimal balance between cost efficiency and inference quality.</p>
        <p>We have optimized Saharsh 4.0 Pro for coding and agentic capabilities, and also we have strengthened the support of MCP as well.</p>
        <p>Saharsh 4.0 Pro represents a significant milestone in our journey toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). By scaling up both pretraining and reinforcement learning (RL), we have achieved higher levels of intelligence. We have seamlessly integrated thinking and non-thinking modes, offering users the flexibility to control the thinking budget. Additionally, we have expanded support for a wide range of languages, enhancing global accessibility.</p>
        <p>Looking ahead, we aim to enhance our models across multiple dimensions. This includes refining model architectures and training methodologies to achieve several key objectives: scaling data, increasing model size, extending context length, broadening modalities, and advancing RL with environmental feedback for long-horizon reasoning. We believe we are transitioning from an era focused on training models to one centered on training agents. Our next iteration promises to bring meaningful advancements to everyone’s work and life.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 3.5 Pro</h2>
        <p>As the latest iteration in the Saharsh series, Saharsh 3.5 Pro achieves comprehensive enhancements across multiple domains, including real-world coding, long-context processing, reasoning, searching, writing, and agentic applications. Saharsh 3.5 Pro performs slightly better than GLM 4.6 in coding related tasks. Details are as follows:</p>
        <ol>
          <li>Longer context window: The context window has been expanded from 128K to 200K tokens, enabling the model to handle more complex agentic tasks.</li>
          <li>Superior coding performance: The model achieves higher scores on code benchmarks and demonstrates better real-world performance in applications such as Claude Code、Cline、Roo Code and Kilo Code, including improvements in generating visually polished front-end pages.</li>
          <li>Advanced reasoning: Saharsh 3.5 Pro shows a clear improvement in reasoning performance and supports tool use during inference, leading to stronger overall capability.</li>
          <li>More capable agents: Saharsh 3.5 Pro exhibits stronger performance in tool use and search-based agents, and integrates more effectively within agent frameworks.</li>
          <li>Refined writing: Better aligns with human preferences in style and readability, and performs more naturally in role-playing scenarios.</li>
        </ol>
        <p>In evaluations across 8 authoritative benchmarks for general model capabilities—including AIME 25, GPQA, LCB v6, HLE, and SWE-Bench Verified—Saharsh 3.5 Pro achieves performance on par with Claude Sonnet 4/Claude Sonnet 4.5 on several leaderboards, solidifying its position</p>
        <p>To better test the model’s capabilities in practical coding tasks, we conducted 74 real-world coding tests within the Claude Code environment. The results show that Saharsh 3.5 Pro surpasses Claude Sonnet 4 and other domestic models in these real-world tests.</p>
        <p>In terms of average token consumption, Saharsh 3.5 Pro is over 30% more efficient than GLM-4.5, achieving the lowest consumption rate among comparable models.</p>
      </div>
      -->
      <!--
      <hr>
      <h1></h1>
      <div>
        <h2 class="nobold">Released Saharsh 3.0 Pro</h2>
        <p>Today we’re introducing Saharsh 3.0 Pro, our most intelligent AI model which is state-of-the-art on a wide range of benchmarks and has slightly better performance than Gemini 2.5 Pro</p>
        <p>Saharsh 3.0 Pro is a thinking model which is capable of reasoning through its thoughts before responding, resulting in enhanced performance and improved accuracy.</p>
        <p>In the field of AI, a system’s capacity for “reasoning” refers to more than just classification and prediction. It refers to its ability to analyze information, draw logical conclusions, incorporate context and nuance, and make informed decisions.</p>
        <p>For a long time, we’ve explored ways of making AI smarter and more capable of reasoning through techniques like reinforcement learning and chain-of-thought prompting. </p>
        <p>With Saharsh 3.0 Pro, we've achieved a new level of performance by combining a significantly enhanced base model with improved post-training. Going forward, we’re building these thinking capabilities directly into all of our models, so they can handle more complex problems and support even more capable, context-aware agents.</p>
        <p>Saharsh 3.0 Pro is our most advanced model for complex tasks. Saharsh 3.0 Pro shows strong reasoning and code capabilities, leading on common coding, math and science benchmarks.</p>
        <p>Saharsh 3.0 Pro performs well across a range of benchmarks requiring advanced reasoning. Without test-time techniques that increase cost, like majority voting, Saharsh 3.0 Pro leads in math and science benchmarks like GPQA and AIME 2025.</p>
        <p>It also scores 18.8% across models without tool use on Humanity’s Last Exam, a dataset designed by hundreds of subject matter experts to capture the human frontier of knowledge and reasoning.</p>
        <p>We’ve been focused on coding performance, and with Saharsh 3.0 Pro we’ve achieved a big leap over 2.5 — with more improvements to come. Saharsh 3.0 Pro excels at creating visually compelling web apps and agentic code applications, along with code transformation and editing. On SWE-Bench Verified, the industry standard for agentic code evals, Saharsh 3.0 Pro scores 63.8% with a custom agent setup.</p>
        <p>Saharsh 3.0 Pro builds on what makes Saharsh models great — native multimodality and a long context window. Saharsh 3.0 Pro ships today with a 1 million token context window, with strong performance that improves over previous generations. It can comprehend vast datasets and handle complex problems from different information sources, including text, audio, images, video and even entire code repositories.</p>
        <p>Developers and enterprises can start experimenting with Saharsh 3.0 Pro in Secure Centrix81's Game Request form now.</p>
        <p>As always, we welcome feedback so we can continue to improve Saharsh’s impressive new abilities at a rapid pace, all with the goal of making our AI more helpful.</p>
      </div>
      -->
      
      <h1>Dec 8, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 2.0 Mini</h2>
        <p>Saharsh 2.0 Mini is the latest generation of large language models in Saharsh Mini series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Saharsh 2.0 Mini delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support.</p>
        <p>Saharsh 2.0 Mini is free to use without any limits and can be accessed <a href="/other-games/28ffa7a0-31e3-43da-b535-39ea89597a60">here</a></p>
      </div>
      <hr>
      <h1>Dec 8, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 2.5 Pro</h2>
        <p>We are introducing Saharsh 2.5 Pro, which incorporates cold-start data before RL. Saharsh 2.5 Pro outperforms Deepseek-R1 by a small amount and achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. Saharsh 2.5 Pro outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.</p>
      </div>
      <hr>
      
      <h1>Dec 1, 2025</h1>
      <div>
        <h2 class="nobold">Released and open sourced Saharsh 1.0 Mini</h2>
        <p>We've trained and open sourced a model called Saharsh 1.0 Mini which offers best-in-class performance, runs at incredible speed across different hardware and easily integrates with other AI tools.</p>
        <p>Saharsh 1.0 Mini is free to use without any limits and can be accessed <a href="/other-games/28ffa7a0-31e3-43da-b535-39ea89597a60">here</a></p>
      </div>
      <h1>November 30, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 2.0 Pro</h2>
        <p>Today, we’re launching Saharsh 2.0 Pro. This model outperforms GPT 4.1 by a small amount and outperforms GPT‑4o and Saharsh 1.5 Pro with major gains in coding and instruction following. It also has a larger context window—supporting up to 1 million tokens of context—and is able to better use that context with improved long-context comprehension. Saharsh 2.0 Pro features a refreshed knowledge cutoff of June 2024.</p>
        <p>Saharsh 2.0 Pro excels at instruction following and tool calling, with broad knowledge across domains. It features a 1M token context window, and low latency without a reasoning step.</p>
        <br>
        <h2 class="nobold">Benchmarks</h2>
        <p>Saharsh 2.0 Pro excels at the following industry standard measures: </p>
        <ol>
          <li>Coding: Saharsh 2.0 Pro scores 54.6% on SWE-bench Verified, improving by 21.4% over GPT‑4o and 26.6% over GPT‑4.5</li>
          <li>Instruction following: On Scale’s MultiChallenge benchmark, a measure of instruction following ability, Saharsh 2.0 Pro scores 38.3%, a 10.5% increase over GPT‑4o.</li>
          <li>Long context: On Video-MME⁠, a benchmark for multimodal long context understanding, Saharsh 2.0 Pro scores 72.0% on the long, no subtitles category, a <strong class="animate-67"><u><i>6.7</i></u></strong>% improvement over GPT‑4o.
        </ol>
        <p>While benchmarks provide valuable insights, we trained Saharsh 2.0 Pro with a focus on real-world utility. Close collaboration and partnership with the developer community enabled us to optimize these models for the tasks that matter most to their applications.</p>
        <p>To this end, Saharsh 2.0 Pro offers exceptional performance at a lower cost. Saharsh 2.0 Pro pushes performance forward at every point on the latency curve.</p>
        <p>These improvements in instruction following reliability and long context comprehension also make Saharsh 2.0 Pro considerably more effective at powering agents, or systems that can independently accomplish tasks on behalf of users, which is perfect for Secure Centrix81's Game Request form.</p>
        <p>Saharsh 2.0 Pro is significantly better than GPT‑4o at a variety of coding tasks, including agentically solving coding tasks, frontend coding, making fewer extraneous edits, following diff formats reliably, ensuring consistent tool usage, and more.</p>
        <p>On SWE-bench Verified, a measure of real-world software engineering skills, Saharsh 2.0 Pro completes 54.6% of tasks, compared to 33.2% for GPT‑4o (2024-11-20) and 49% for o3-mini (high). This reflects improvements in model ability to explore a code repository, finish a task, and produce code that both runs and passes tests.</p>
        <p>Saharsh 2.0 Pro is much more reliable at code diffs across a range of formats. Saharsh 2.0 Pro more than doubles GPT‑4o’s score on Aider’s polyglot diff benchmark, and even beats GPT‑4.5 by 8%. This evaluation is both a measure of coding capabilities across various programming languages and a measure of model ability to produce changes in whole and diff formats. We’ve specifically trained Saharsh 2.0 Pro to follow diff formats more reliably, which allows developers to save both cost and latency by only having the model output changed lines, rather than rewriting an entire file. We’ve increased output token limits for Saharsh 2.0 Pro to 32,768 tokens. </p>
        <p>Saharsh 2.0 Pro also substantially improves upon GPT‑4o in frontend coding, and is capable of creating web apps that are more functional and aesthetically pleasing. In our head-to-head comparisons, paid human graders preferred Saharsh 2.0 Pro’s websites over GPT‑4o’s 80% of the time.</p>
        <p>Beyond the benchmarks above, Saharsh 2.0 Pro is better at following formats more reliably and makes extraneous edits less frequently. In our internal evals, extraneous edits on code dropped from 9% with GPT‑4o to 2% with Saharsh 2.0 Pro.</p>
        <p>Saharsh 2.0 Pro scores 60% higher than GPT‑4o on Windsurf’s internal coding benchmark, which correlates strongly with how often code changes are accepted on the first review. Their users noted that it was 30% more efficient in tool calling and about 50% less likely to repeat unnecessary edits or read code in overly narrow, incremental steps. These improvements translate into faster iteration and smoother workflows for engineering teams.</p>
        <p>Qodo tested Saharsh 2.0 Pro head-to-head against other leading models on generating high-quality code reviews from GitHub pull requests using a methodology inspired by their fine-tuning benchmark. Across 200 meaningful real-world pull requests with the same prompts and conditions, they found that Saharsh 2.0 Pro produced the better suggestion in 55% of cases⁠. Notably, they found that Saharsh 2.0 Pro excels at both precision (knowing when not to make suggestions) and comprehensiveness (providing thorough analysis when warranted), while maintaining focus on truly critical issues.</p>
        <br>
        <h2 class="nobold">Instruction Following</h2>
        <p>Multi-turn instruction following is critical for many developers—it’s important for the model to maintain coherence deep into a conversation, and keep track of what the user told it earlier. We’ve trained Saharsh 2.0 Pro to be better able to pick out information from past messages in the conversation, allowing for more natural conversations. The MultiChallenge benchmark from Scale is a useful measure of this capability, and Saharsh 2.0 Pro performs 10.5% better than GPT‑4o.</p>
        <p>Saharsh 2.0 Pro also scores 87.4% on IFEval, compared to 81.0% for GPT‑4o. IFEval uses prompts with verifiable instructions (for example, specifying content length or avoiding certain terms or formats).</p>
        <p>Better instruction following makes existing applications more reliable, and enables new applications previously limited by poor reliability. Early testers noted that Saharsh 2.0 Pro can be more literal, so we recommend being explicit and specific in prompts.</p>
        <p>Saharsh 2.0 Pro was 53% more accurate than GPT‑4o on an internal benchmark of Blue J’s most challenging real-world tax scenarios. This jump in accuracy—key to both system performance and user satisfaction—highlights Saharsh 2.0 Pro’s improved comprehension of complex regulations and its ability to follow nuanced instructions over long contexts. For Blue J users, that means faster, more reliable tax research and more time for high-value advisory work.</p>
        <p>Saharsh 2.0 Pro delivered a nearly 2× improvement on Hex’s most challenging SQL evaluation set,⁠ showcasing significant gains in instruction following and semantic understanding. The model was more reliable in selecting the correct tables from large, ambiguous schemas—an upstream decision point that directly impacts overall accuracy and is difficult to tune through prompting alone. For Hex, this resulted in a measurable reduction in manual debugging and a faster path to production-grade workflows.</p>
        <br>
        <h2 class="nobold">Long Context</h2>
        <p>Saharsh 2.0 Pro can process up to 1 million tokens of context—up from 128,000 for previous GPT‑4o models. 1 million tokens is more than 8 copies of the entire React codebase, so long context is a great fit for processing large codebases, or lots of long documents.</p>
        <p>We trained Saharsh 2.0 Pro to reliably attend to information across the full 1 million context length. We’ve also trained it to be far more reliable than GPT‑4o at noticing relevant text, and ignoring distractors across long and short context lengths. Long-context understanding is a critical capability for applications across legal, coding, customer support, and many other domains.</p>
        <p>Few real-world tasks are as straightforward as retrieving a single, obvious needle answer. We find users often need our models to retrieve and understand multiple pieces of information, and to understand those pieces in relation to each other. To showcase this capability, we’re open-sourcing a new eval: OpenAI-MRCR (Multi-Round Coreference). </p>
        <p>OpenAI-MRCR tests the model’s ability to find and disambiguate between multiple needles well hidden in context. The evaluation consists of multi-turn synthetic conversations between a user and assistant where the user asks for a piece of writing about a topic, for example "write a poem about tapirs" or "write a blog post about rocks". We then insert two, four, or eight identical requests throughout the context. The model must then retrieve the response corresponding to a specific instance (e.g., “give me the third poem about tapirs”).</p>
        <p>The challenge arises from the similarity between these requests and the rest of the context—models can easily be misled by subtle differences, such as a short story about tapirs rather than a poem, or a poem about frogs instead of tapirs. We find that Saharsh 2.0 Pro outperforms GPT‑4o at context lengths up to 128K tokens and maintains strong performance even up to 1 million tokens.</p>
        <p>Thomson Reuters tested Saharsh 2.0 Pro with CoCounsel, their professional grade AI assistant for legal work. Compared to GPT‑4o, they were able to improve multi-document review accuracy by 17% when using Saharsh 2.0 Pro across internal long-context benchmarks—an essential measure of CoCounsel’s ability to handle complex legal workflows involving multiple, lengthy documents. In particular, they found the model to be highly reliable at maintaining context across sources and accurately identifying nuanced relationships between documents, such as conflicting clauses or additional supplementary context—tasks critical to legal analysis and decision-making.</p>
        <p>Carlyle used Saharsh 2.0 Pro to accurately extract granular financial data across multiple, lengthy documents—including PDFs, Excel files, and other complex formats. Based on their internal evaluations, it performed 50% better on retrieval from very large documents with dense data and was the first model to successfully overcome key limitations seen with other available models, including needle-in-the-haystack retrieval, lost-in-the-middle errors, and multi-hop reasoning across documents.</p>
        <p>In addition to model performance and accuracy, developers also need models that respond quickly to keep up with and meet users’ needs. We've improved our inference stack to reduce the time to first token, and with prompt caching, you can cut latency even further while saving on costs. In our initial testing, latency to first token for Saharsh 2.0 Pro was approximately fifteen seconds with 128,000 tokens of context, and a minute for a million tokens of context.</p>
        <br>
        <br>
        <p>As always, Secure Centrix81's Saharsh language models are completely <b>free</b>! To use it, you just have to request for an AI to make your game on Secure Centrix. Your request will be approved in 1-5 business days if you are a member (<strong class="animate-67"><u><i>6-7</i></u></strong> business days if you are not a member)</p>
      </div>
      <hr>
      <h1>November 29, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 1.5 Pro</h2>
        <p>Saharsh 1.5 Pro is our versatile, high-intelligence flagship model. It is currently the best model we have for most tasks, and is currently our most capable model.</p>
        <p>Saharsh 1.5 Pro matches and passes GPT‑4o performance on text in English and code by a small amount. It also comes with significant improvement on text in non-English languages, while also being much faster than GPT-4 Turbo. Saharsh 1.5 Pro is especially better at vision and audio understanding compared to GPT-4 Turbo.</p>
      </div>
      <hr>
      <h1>November 29, 2025</h1>
      <div>
        <h2 class="nobold">Released Saharsh 1.0 Pro, Secure Centrix81's offical AI</h2>
        <p>We've trained a model called Saharsh 1.0 Pro which interacts in a conversational way. The dialogue format makes it possible for Saharsh 1.0 Pro to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.</p>
        <p>Saharsh 1.0 Pro passes GPT 3.5 in performance by a small amount in text and code.</p>
      </div>
    </div>
  </body>
</html>
